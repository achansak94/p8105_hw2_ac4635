---
title: "Homework 2"
author: "JR Chansakul"
date: 2020-09-28
output: github_document
  
---

```{r}
library(tidyverse)
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset. 

```{r}
trashwheel_df =
  read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_ball = round(sports_balls),
    sports_ball = as.integer(sports_balls)
  )
```

This dataset contains information for the Mr. Trashwell trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash 

Read precipitation data!

```{r}
precip_2018 =
  read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>%  
  janitor::clean_names() %>% 
  drop_na(month) %>% 
    mutate(year = 2018) %>% 
    relocate(year)
  
precip_2017 =
  read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>%  
  janitor::clean_names() %>% 
  drop_na(month) %>% 
    mutate(year = 2017) %>% 
    relocate(year)

```

Now combine annual precipitation 

```{r}
month_df =
    tibble(
      month_num = 1:12
    )

precip_df = 
  bind_rows(precip_2018, precip_2017)
```

This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month precipitation data. In this dataset:

* The median number of sports balls found in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`
* The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.



## Problem 2

## Problem 2: Part 1
Import and clean NYC transit data.

```{r NYC_transit_data, collapse=TRUE}
NYC_transit_df =
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
      col_types = cols(
      Route8 = col_character(),
      Route9 = col_character(),
      Route10 = col_character(),
      Route11 = col_character()
      )) %>% 
    janitor::clean_names() %>% 
    select(line:ada, -staffing, -staff_hours, -exit_only) %>% 
    mutate(entry = recode(entry, 'YES' = TRUE, 'NO' = FALSE) 
    )
    
```

This dataset contains entry and exit information for the NYC subway station with the following variables of interest filtered from the imported dataset: `r names(NYC_transit_df)`. I kept variables with key information such as station name, entrance type and ADA compliance and removed variables such as exit and entrance location. Additionally, the entry variable was converted from a character to a logical variable. The dataset has a total of `r nrow(NYC_transit_df)` rows and `r ncol(NYC_transit_df)` columns with each row representing an entrance or exit. 
Each row contains the line, name, location (latitude, longitude) and route(s) associated with the station. The dataset is not tidy because the route 1 through route 11 columns contains variable information (e.g. subways on that line) and has many NAs.  

## Problem 2: Part 2

```{r Transit_Details_Code, collapse=TRUE}
count(distinct(NYC_transit_df, line, station_name))

count(filter(NYC_transit_df, ada == TRUE) %>%
        distinct(line, station_name))

count(filter(NYC_transit_df, vending == "NO") %>%
  filter (entry == "FALSE"))

count(filter (NYC_transit_df, vending == "NO"))

(count(filter(NYC_transit_df, vending == "NO") %>%
  filter (entry == "TRUE")))/(count(filter (NYC_transit_df, vending == "NO")))

```

There are `r count(distinct(NYC_transit_df, line, station_name))` distinct stations.

There are `r count(filter(NYC_transit_df, ada == TRUE) %>% distinct(line, station_name))` stations that are ADA compliant. 

Among the `r count(filter (NYC_transit_df, vending == "NO"))` subway entrances/exits without vending, `r count(filter(NYC_transit_df, vending == "NO") %>% filter (entry == "TRUE"))` allowed entry. The proportion of station entrances/exits without vending that allow entry is `r (count(filter(NYC_transit_df, vending == "NO") %>% filter (entry == "TRUE")))/(count(filter (NYC_transit_df, vending == "NO")))`.

## Problem 2: Part 3

Reformated the data so that route number and route name are distinct variables.

```{r Tidy_Subway_Data}
NYC_transit_tidy =
  pivot_longer(
    NYC_transit_df, 
    route1:route11,
    names_to = "route_number", 
    values_to = "route_names") %>% 
    drop_na(route_names) 

view (NYC_transit_tidy) # view dataset 
```

After cleaning the dataset, there are a total of `r nrow(NYC_transit_tidy)` rows and `r ncol(NYC_transit_tidy)` columns. Dataset is now tidy because the NA responses have been removed from the route_names variable.  

The code chunk below creates a dataset that counts distinct serve the A Train.

```{r }

# Count distinct stations that serve A train
  Distinct_A_stations= 
    NYC_transit_tidy %>%
    filter(route_names == 'A') %>% 
    distinct(station_name, line) %>%
    count()
    
# Count stations that serve A train that are ADA compliant
ADA_compliant_A_trains = 
  NYC_transit_tidy %>% 
  filter(route_names == 'A', ada == TRUE) %>% 
  distinct(station_name, line) %>% 
  count()  
```

There are `r Distinct_A_stations` distinct stations that serve the A train and `r ADA_compliant_A_trains` are ADA compliant.


## Problem 3

Clean and tidy the dataset in pols-month.csv.

```{r pols_month_data}

pols_month_df = 
  read_csv("./data/pols-month.csv") %>%
  janitor::clean_names() %>% 
  separate (mon, into = c("Year", "Month", "Day")) %>% 
  mutate(Month = as.numeric(Month)) %>% 
  mutate(Month = month.abb[Month]) %>% 
  pivot_longer(
    cols = starts_with("prez"),
    names_to = "president_party",
    values_to = "value") %>% 
  filter (value==1) %>% 
  mutate(president_party = recode(
    president_party, `prez_gop` = 'gop', `prez_dem` = 'dem')) %>% 
  select(-Day, -value) %>% 
  arrange (Year, Month) %>% 
  view ()

view(pols_month_df)
```

Clean and tidy the dataset in the snp dataset.

```{r snp_dataset}
snp_df = 
  read_csv("./data/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("Month", "Day", "Year")) %>% 
  relocate(Year, Month) %>% 
  mutate(Month = as.numeric(Month)) %>% 
  mutate(Month = month.abb[Month]) %>%
  arrange (Year, Month) %>%
  select (-Day) %>%
  view()
```


Clean and tidy the dataset in the umeployment dataset.

```{r unemployment_dataset}

unemployment_tidy_df =
  read_csv("./data/unemployment.csv") %>% 
  pivot_longer(
    cols = Jan:Dec,
    names_to = "Month",
    values_to = "Unemployment_rate") %>% 
  mutate(Year = as.character(Year)) %>% 
  view()
```


Last step, join the datasets by merging snp into pols, and then merging unemployment into the result.

```{r}
Combine_data = 
  left_join(pols_month_df, snp_df, by = c("Year", "Month"))

Final_df = 
  left_join(Combine_data, unemployment_tidy_df, by = c("Year", "Month"))

#View combined datasets 
view(Combine_data)
view(Final_df)

```

Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables):


The original pols-month_df dataset contained 822 observations and 9 variables listing the the number of democratic and republican governors, US Senators, and US House of Representatives as well as the president's political affiliation at a moment in time. The dataset was restricted to the democractic and republican parties. After tidying the dataset, we have political information between the years `r min(pull(pols_month_df, Year))` and `r max(pull(pols_month_df, Year))` with `r nrow(pols_month_df)` observations and `r ncol(pols_month_df)` variables in the dataset. These are the following variables in this dataset: `r ls(pols_month_df)`. I created a "prez_party" variable indicated the incumbent's president political party. 

After the “snp_df” dataset, it contained `r nrow(snp_df)` observations and `r ncol(pols_month_df)` variables in the dataset, which were `r ls(snp_df)`. This datset provides information on the Standard & Poor’s stock market index (S&P) from `r min(pull(snp_df, Year))` to `r max(pull(snp_df, Year))`. I separated the dates into month, day and year like the pols-month_df dataset and removed day from the “snp_df” dataset. The variable "close" represents the closing values of the S&P stock index on that specific date.

After tidying the unemployment_tidy_df dataset, it contained `r nrow(unemployment_tidy_df)` observations and `r ncol(unemployment_tidy_df)` variables in the dataset, which were `r ls(unemployment_tidy_df)`. I created two variables, month and unemployment rate in our tidy dataset using pivot_longer. This datset provides unemployment rate by month from `r min(pull(unemployment_tidy_df, Year))` to `r max(pull(unemployment_tidy_df, Year))`.


The final dataset was combined using left_join and contains `r nrow(Final_df)` rows by `r ncol(Final_df)` columns that includes NA for empty observations for each variable .. The dataset contains on politicians' political affiliation, unemploymnet rate and the S&P stock market from `r min(pull(Final_df, Year))` to `r max(pull(Final_df, Year))`. 

decribe the 3 datasets and how you wrangled the datsets. The variables in the final dataset 


